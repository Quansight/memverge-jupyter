{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73dc661d-a91c-488f-af06-0823298bcc1a",
   "metadata": {},
   "source": [
    "# Using napari to process a large dataset (brain imaging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f35fdc-cf3e-4fc0-b393-bf4d9e9de013",
   "metadata": {},
   "source": [
    "In this notebook, we will use napari and scikit-image to process a large brain imaging dataset and detect the edges of the brain images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b2a400-93b7-47f4-80d5-86aba5805a1c",
   "metadata": {},
   "source": [
    "Since [napari](https://napari.org) is a GUI application, and we are using a docker image (`jupyter-server`) that doesn't provide a desktop server on our MMCloud instance, we need to set up some environment variables so that napari can run in headless mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f187b-8fbe-4b4b-8abd-ee818ff6db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env QT_QPA_PLATFORM=offscreen\n",
    "%set_env XDG_RUNTIME_DIR=/mnt/napari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1849218-f662-406d-a1d8-d95155e3c8ca",
   "metadata": {},
   "source": [
    "Next, we will install the Python dependencies we will use for our operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install napari[all] tornado==6.1 dask-image napari-compressed-labels-io -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eab912-f775-41cc-a0be-bd1d7bd9d348",
   "metadata": {},
   "source": [
    "## Downloading files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d04ae0-c1f7-4003-bd56-30a1b4b4ac49",
   "metadata": {},
   "source": [
    "The dataset we are using here is a high-resolution human brain imaging dataset. This dataset was originally described in [Edlow, B.L., Mareyam, A., Horn, A. _et al._ 7 Tesla MRI of the ex vivo human brain at 100 micron resolution. Sci Data 6, 244 (2019)](https://doi.org/10.1038/s41597-019-0254-8). We will download this dataset as a zipfile containing a set of TIFF files, and extract it to our desired location.\n",
    "\n",
    "Note that `volume` points to the Volume we set up when creating our MMCloud Job for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa652a5-f941-4a85-bb39-c1e2e52b34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = \"/mnt/napari\"\n",
    "url = \"https://s3.amazonaws.com/openneuro.org/ds002179/derivatives/sub-EXC004/synthesized_FLASH25_100um_tiff_images/Synthesized_FLASH25_100um_TIFF_Axial_Images.zip?versionId=6L9rb8Lv1whb1eXQVTgnYh1bSSwc_5Hj\"\n",
    "filename = f\"{volume}/Synthesized_FLASH25_100um_TIFF_Axial_Images.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e21cd-ca85-4a78-90e5-f10955d5da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open(filename, 'wb').write(r.content)\n",
    "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(f\"{volume}/.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1dc61a-6555-4fa3-b075-f5aa9805665f",
   "metadata": {},
   "source": [
    "The TIFF files are now available for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461acece",
   "metadata": {},
   "source": [
    "## Reading image files with napari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6f80b-ed8e-4a6b-83df-6d509af572f9",
   "metadata": {},
   "source": [
    "We will use [dask-image](https://image.dask.org/en/latest/) to load up our TIFF files into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac449d5-7b38-4463-87e5-5cf796c547b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "from dask_image.imread import imread\n",
    "\n",
    "images = imread(f'{volume}/SYNTHESIZED_TIFF_Images_Raw/Synthesized_FLASH25_100um_TIFF_Axial_Images/Synthesized_FLASH25_Axial_*.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793782a-061e-4bc6-be97-85c44f3474a8",
   "metadata": {},
   "source": [
    "Now, we will set up our napari `Viewer` (even though it won't be shown since we are running in headless mode) and add our images to the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3947d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(show=True)\n",
    "viewer.add_image(images, name='brain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08123c6-659b-4f96-936f-7a262df867ed",
   "metadata": {},
   "source": [
    "## Detecting the edges of the brain images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b93c29-431d-4a52-bd82-556efe2750af",
   "metadata": {},
   "source": [
    "The brain images contained in this dataset form a stack of image arrays, showing different slices of the brain being processed.\n",
    "\n",
    "We will look at each of these slices and try to detect the edges of each of these images using the [Canny edge detector from scikit-image](https://scikit-image.org/docs/stable/auto_examples/edges/plot_canny.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a079a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import img_as_ubyte\n",
    "from skimage.feature import canny\n",
    "from dask.array import from_array, stack\n",
    "\n",
    "res = []\n",
    "for i in range(images.shape[0]):\n",
    "    res.append(img_as_ubyte(from_array(canny(images[i], sigma=1, low_threshold=25, high_threshold=50))))\n",
    "border = stack(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c70f3-23dc-4908-a19a-b1d3dfeca9a5",
   "metadata": {},
   "source": [
    "Note that both `images` and `border` are dask arrays: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70635e89-7e72-4165-b754-2e43b29e409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "border"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f0a0f-5973-45f9-9eff-26538976e728",
   "metadata": {},
   "source": [
    "Finally, we can add this image to napari highlighting the edges of each of the brain image slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f27e61-0857-49cd-aa3b-1055de3bbcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(border, name=\"border-labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b1cecc",
   "metadata": {},
   "source": [
    "## Using a napari plugin to save layer data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46aebce",
   "metadata": {},
   "source": [
    "The [napari-compressed-labels-io](https://www.napari-hub.org/plugins/napari-compressed-labels-io) plugin for napari allows us to save the current layers data as an zarr file, including the layer metadata. We will create this file and download it for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf3009e-fc8f-4a25-af7e-c48c5d14cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_compressed_labels_io import labels_to_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f76a7f-d094-444a-8169-95cbdc7deec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671f7a5-2bcb-4dab-8f64-5c964ebcdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = viewer.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e605c-5add-4c41-b892-d092eaf7bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b7f1c-4be8-4025-8e91-94cee790039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_zarr(f\"{volume}/edges.zarr\", np.asarray(edges.data), edges.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dee819-bb29-4727-9044-3f72fbc42d85",
   "metadata": {},
   "source": [
    "To make it easier to download these files, we will add them to a zip archive first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "with zipfile.ZipFile('edges.zip', 'w') as zip_ref:\n",
    "    for file in glob.glob(f\"{volume}/edges.zarr/*\"):\n",
    "        zip_ref.write(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d0090-d815-4950-8239-c945c951e794",
   "metadata": {},
   "source": [
    "Our file \"edges.zip\" is now ready to be downloaded from the Jupyter interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61928d2a-4b91-40c0-8048-8008cdc268ad",
   "metadata": {},
   "source": [
    "The labels layer we just saved can then be recovered by using"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce0ec61-396e-45a4-910f-4af76457ee90",
   "metadata": {},
   "source": [
    "```python\n",
    "border = get_zarr_labels(\"edges.zarr\")(\"edges.zarr\")\n",
    "viewer.add_labels(border[0][0])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
